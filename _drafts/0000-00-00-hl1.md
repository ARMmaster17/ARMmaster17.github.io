---
layout: post
title:  "Home Lab Tutorials Part 1: Proxmox Setup"
date:   2020-05-13 12:00:00 -0500
categories: container vm pastebin
---
I wanted to create a series of articles on how my homelab is built, to serve as documentation for myself and to help others along the path.

# Objectives
I have needed to reset my homelab several times for various hardware and software reasons. This time around, I wanted to meet the following goals as I rebuilt my cluster:
1. NO MANUAL CONFIGURATION. All containers should be provisioned, managed, and controlled purely through a centralized system such as Ansible. This makes it easy to reperoduce machines and makes it easy to scale.
2. Entire clustur should be (theoretically) infinitely scalable. This will require adaptive tools such as Ceph and SDN. More on Ceph later.
3. Entire cluster should be completely fault-tolerant. This will be trick for my cluster as I will be using consumer hardware without fancy failover network and power systems that big datacenters have.

# High-level architecture
## Hardware
My current homelab consists of three machines. They are all Intel i5 machines that range from 3rd to 4th gen. If you are looking for hardware to get started, I recommend buying refurbished hardware. Each of these machines can be bought for $140-$250 each. What you are looking for is something Intel-based, as consumer-grade AMD hardware tends to have issues with virtualization.

There are three upgrades you will probably want to consider if you go this route. First and foremost is RAM. Especially if you will be using Ceph like me, you will want 16GB of RAM per machine at minimum. This upgrade is only about $60-$80 and is well worth the money. Obviously if you can get more, you should. Older systems like mine max out at 16 GB of RAM, but newer ones can support up to 64 GB.

Another upgrade you will want to look at is a disk controller. Consumer motherboards usually only have 2-4 SATA ports on board. If you want lots of disks you will need a way to get more ports. Now, a word of caution from my own experiences. Do NOT go out and buy a random RAID or SATA controller card. I bought a Vantec card from Microcenter for $45 and it was actually the cause of one of my resets because it killed my Ceph cluster and I lost a good chunk of data. Look for actual server-grade HBA cards like a Perc-i9. One more thing to consider while we're talking about disks, you will need approximately 1 GB of RAM per disk, or 1 GB of RAM per TB of raw storage on your disks, whichever is higher. This is for Bluestore to cache data. This setting is configurable but in my experience Ceph tends to ignore you if you tell it to take less than 1 GB.